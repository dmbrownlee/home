# Rename this file to terraform.tfvars after supplying your own site
# specific values.
#=============
# Proxmox
#=============
# Here is where we specify the URL for the web API for the Proxmox cluster.
endpoint = "https://pve1.example.com:8006/"

# Here we specify which Proxmox node on which to store the VM templates and
# the name of the storage we use for storing ISO images (actually qcow2
# cloud-init images ).
template_node = "pve3"
iso_storage = {
  node = "pve3",
  name = "truenas1"
}

# Here is where we specify the node interface to which we add the VLANs. The
# switch port patched to this interface should be configured as a VLAN trunk.
node_vlan_interfaces = {
  pve1 = "vmbr0"
  pve2 = "vmbr0"
  pve3 = "vmbr0"
}

#=============
# Cloud-init
#=============
# This is where we specify the user credentials for the administrative user
# cloud-init will create on each VM cloned from a cloud-init template image.
# Since we will be using Ansible for configuration management, it makes sense
# for this to be the "ansible" user.  If any other users need to be configured,
# Ansible can do that.  After Terraform has created and booted the VM, it will
# run Ansible to do further machine configuration.  The corresponding private
# SSH key should be added to your SSH agent as SSH is usually configured to
# disallow password logins.  Note, the public key does not include the comment
# you see at the end of the line in the .pub file.
ciuser     = "ansible"
cipassword = "AGoodPassword"
cipubkey   = ["ssh-rsa aaabbbcccdddeeefffggghhhiiijjjkkklllmmmnnnooopppqqqrrrssstttuuuvvvwwwxxxyyyzzzAAABBBCCCDDDEEEFFFGGGHHHIIIJJJKKKLLLMMMNNNOOOPPPQQQRRRSSSTTTUUUVVVWWWXXXYYYZZZ111222333444555666777888999000=="]

#=============
# Ansible
#=============
# ssh_private_key_files is a map of paths to SSH private key files indexed by
# username.  Here, we specify the location of the "ansible" user's private
# SSH key that needs to be known when Terraform runs ansible-playbook.
ssh_private_key_files = {
  ansible = "~/keys/ansible"
}

#=============
# Site VLANs
#=============
# vlans is a map of site VLAN objects indexed by name.  Besides the VLAN ID,
# each VLAN specifies networking configuration for the netblock the VLAN uses
# in case the virtual machines connected to the VLAN do not use DHCP for
# network configuration.
vlans = [
  {
    vlan_id = 10,
    comment = "PROVISIONING",
    ipv4_gateway = "192.168.10.254",
    ipv4_dns_servers = [ "192.168.10.254" ]
  },
  {
    vlan_id = 1000,
    comment = "LABS",
    ipv4_gateway = "192.168.81.254",
    ipv4_dns_servers = [ "192.168.80.254" ]
  },
  {
    vlan_id = 1001,
    comment = "K8S",
    ipv4_gateway = "192.168.81.254",
    ipv4_dns_servers = [ "192.168.81.254" ]
  },
  {
    vlan_id = 1002,
    comment = "K3S",
    ipv4_gateway = "192.168.81.254",
    ipv4_dns_servers = [ "192.168.82.254" ]
  },
  {
    vlan_id = 80,
    comment = "DMZ",
    ipv4_gateway = "192.168.83.254",
    ipv4_dns_servers = [ "192.168.83.254" ]
  },
]

#=========================
# cloud-init image files
#=========================
# cloud_init_images stores a map of distro cloud-init images that should exist
# within Proxmox storage.  Terraform will download these to the Proxmox
# cluster's ISO storage.  Note, Proxmox does not recognize the .qcow2 extension
# so the resulting filename, as it appears in the Proxmox ISO storage, needs to
# end in .img.
cloud_init_images = {
  debian12-genericcloud-20240102 = {
    url       = "https://cloud.debian.org/images/cloud/bookworm/20240102-1614/debian-12-genericcloud-amd64-20240102-1614.qcow2",
    file_name = "debian-12-genericcloud-amd64-20240102.qcow2.img"
  },
  debian12-genericcloud-20240211 = {
    url       = "https://cloud.debian.org/images/cloud/bookworm/20240211-1654/debian-12-genericcloud-amd64-20240211-1654.qcow2",
    file_name = "debian-12-genericcloud-amd64-20240211.qcow2.img"
  }
}

#============================
# Template virtual machines
#============================
# vm_templates describes a map of virtual machine templates Terraform will
# create from the disk images listed above in cloud_init_images. The keys for
# the map are the names of the template virtual machines and the objects they
# refer to contain the name of the cloud-init image to use, the Proxmox VM id
# to use, and the VLAN the template will default to using.
vm_templates = {
  debian12-genericcloud-20240102 = {
    vm_id            = 999,
    cloud_init_image = "debian12-genericcloud-20240102",
    vlan             = 1000
  },
  debian12-genericcloud-20240211 = {
    vm_id            = 998,
    cloud_init_image = "debian12-genericcloud-20240102",
    vlan             = 1000
  }
}

#=================
# Load Balancers
#=================
load_balancers = [
  {
    hostname = "lb1",
    pve_node = "pve1",
    vm_id = 501,
    cloud_init_image = "debian12-genericcloud-20240102",
    mac_address = "ca:fe:01:06:01:01",
    ipv4_address = "192.168.83.251/24"
  },
  {
    hostname = "lb2",
    pve_node = "pve2",
    vm_id = 502,
    cloud_init_image = "debian12-genericcloud-20240102",
    mac_address = "ca:fe:01:06:02:01",
    ipv4_address = "192.168.83.252/24"
  },
]

#=============
# Kubernetes
#=============
control_plane_nodes = [
  { hostname = "k8scp1", pve_node = "pve1", vm_id = 401, mac_address = "ca:fe:01:05:01:01" },
  { hostname = "k8scp2", pve_node = "pve2", vm_id = 402, mac_address = "ca:fe:01:05:02:01" },
  { hostname = "k8scp3", pve_node = "pve3", vm_id = 403, mac_address = "ca:fe:01:05:03:01" }
]

worker_nodes = [
  { hostname = "k8sw1", pve_node = "pve1", vm_id = 404, mac_address = "ca:fe:01:05:04:01" },
  { hostname = "k8sw2", pve_node = "pve2", vm_id = 405, mac_address = "ca:fe:01:05:05:01" }
]
